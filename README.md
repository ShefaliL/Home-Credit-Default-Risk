# Home-Credit-Default-Risk
In todayâ€™s world, many people struggle to get loans due to insufficient credit histories or even non-existing credit records, which often tend to be untrustworthy lenders who exploit them. Home Credit acts towards expanding the financial inclusion for the unbanked by providing a secure borrowing experience. Home credit utilizes several alternative data and methods to predict repayment abilities. To ensure that this underserved demographic has a favorable loan experience, we will be using machine learning and statistical methods to determine these predictions. This ensures that the clients who are capable of repayment will be granted a loan and are not rejected by any means. Furthermore, they will be provided with a loan maturity plan and a repayment calendar that will accredit our clients to be more successful. 

Diagram: This is a block diagram to understand the workflow of the data.

![image](https://github.com/ShefaliL/Home-Credit-Default-Risk/assets/76598077/68a450c7-17fa-4672-9547-8697b5e54c39)

 The data is tackled in Phases. Our goal in this phase is to work on the Home Credit Default Risk (HCDR) data and perform some cleaning and preprocessing techniques and modeling techniques with pipelining to predict whether a person receives a loan or not. The initial phase consists of merging all subordinate files, cleaning and analyzing the data, and performing some exploratory data analysis. Furthermore, we  also apply some preprocessing steps which also include dividing the data into numerical and categorical values. The first phase also includes training the model without feature engineering and hyperparameter tuning

 Following are few insights from the Exploratory Data Analysis:
 
![image](https://github.com/ShefaliL/Home-Credit-Default-Risk/assets/76598077/52b288f1-aa7e-45e0-a675-3eed5017b48a)


![image](https://github.com/ShefaliL/Home-Credit-Default-Risk/assets/76598077/7454049a-446c-4f3e-83a5-fb303e4a59da)



The second phase consists of creating new features from the existing features that could add on as a good predictor in the existing dataset. This phase includes the creation of 11 new features from the existing important features and the creation of a modeling pipeline where we determined the best hyperparameters (hyperparameter tuning) for the models to select the best model. The testing data was then parsed through the best model to get the test results. The best model for the second phase was the Random Forest Classifier with a training accuracy of 92.4% and a test roc score of 0.72814.

The third and final phase included the creation of a Multi-Layer Perceptron (MLP) neural network using Pytorch. The Artificial Neural Network model yielded a training score of 91.95% and a test roc score of 0.71225.
